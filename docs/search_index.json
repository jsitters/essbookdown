[["index.html", "ESS Final Project Chapter 1 Intro", " ESS Final Project Jan Sitterson 2022-03-24 Chapter 1 Intro This is an R Bookdown document of the data analysis skills I have learned through ESS 580. "],["r-markdown.html", "Chapter 2 R Markdown 2.1 SiteDescription 2.2 Data Acquisition and Plotting tests 2.3 Static Data Plotter 2.4 Interactive Data Plotter 2.5 Assignment Prompt 2.6 DyGraph example 2.7 Poudre Paragraph", " Chapter 2 R Markdown The Poudre River at Lincoln Bridge is: Downstream of only a little bit of urban stormwater Near Odell Brewing CO Near an open space area and the Poudre River Trail Downstream of many agricultral diversions 2.1 SiteDescription 2.2 Data Acquisition and Plotting tests q &lt;- readNWISdv(siteNumbers = &#39;06752260&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2022-01-01&#39;) %&gt;% rename(q = &#39;X_00060_00003&#39;) 2.3 Static Data Plotter ggplot(q, aes(x = Date, y = q)) + geom_line() + ylab(&#39;Q (cfs)&#39;) + ggtitle(&#39;Discharge in the Poudre River, Fort Collins&#39;) ## Warning: Removed 31 row(s) containing missing values (geom_path). 2.4 Interactive Data Plotter q_xts &lt;- xts(q$q, order.by = q$Date) dygraph(q_xts) %&gt;% dyAxis(&quot;y&quot;, label = &quot;Discharge (cfs)&quot;) 2.5 Assignment Prompt This assignment will be primarily about demonstrating some expertise in using RMarkdown, since we will be using Rmds as the primary form of homework and assignments. With that in mind, your assignment for this homework is to: 2.6 DyGraph example dygraph(q_xts) %&gt;% dyRangeSelector() 2.7 Poudre Paragraph The Cache la Poudre is a snow melt fed watershed in Northern Colorado. Much of the Poudre is under limited human impact, with almost half of the river designated as a Wild and Scenic river. The City of Fort Collins is concerned that microplastics in freshwater environments could impact both ecological and human health since the Cache la Poudre River watershed is a main source of drinking and irrigation water for Northern Colorado. Utility managers are interested in finding out a way to remove microplastics through the WWTP as described in the research by Ngo. "],["data-wrangle.html", "Chapter 3 Data Wrangle 3.1 Question (1) 3.2 Question (2) 3.3 Question (3) 3.4 Question (4) 3.5 Question (5)", " Chapter 3 Data Wrangle Pulling data from files and reading them into R for analysis. library(tidyverse) library(tidyr) library(ggthemes) library(lubridate) # Now that we have learned how to munge (manipulate) data # and plot it, we will work on using these skills in new ways #knitr::opts_knit$set(root.dir=&#39;..&#39;) ####-----Reading in Data and Stacking it ----- #### #Reading in files files &lt;- list.files(&#39;data&#39;,full.names=T) ##&#39;data&#39; will work if not inline printing #Read in individual data files ndmi &lt;- read_csv(files[1]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndmi&#39;) ndsi &lt;- read_csv(files[2]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndsi&#39;) ndvi &lt;- read_csv(files[3])%&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndvi&#39;) # Stack as a tidy dataset full_long &lt;- rbind(ndvi,ndmi,ndsi) %&gt;% gather(key=&#39;site&#39;,value=&#39;value&#39;,-DateTime,-data) %&gt;% filter(!is.na(value)) ##new word is called pivot_longer 3.1 Question (1) What is the correlation between NDVI and NDMI? - here I want you to convert the full_long dataset in to a wide dataset using the function spread and then make a plot that shows the correlation s a function of if the site was burned or not (x axis should be ndmi) You should exclude winter months and focus on summer months full_wide&lt;-spread(full_long, key=&#39;data&#39;, value=&#39;value&#39;)%&gt;% mutate(month=month(DateTime))%&gt;% filter( month %in% c(5,6,7,8,9)) ggplot(full_wide, aes(x=ndmi, y=ndvi,color=site ))+ geom_point(shape=1) + theme_few() + scale_color_few() + theme(legend.position=c(0.8,0.8)) ## Warning: Removed 19 rows containing missing values (geom_point). print(&quot;There is a positive correlation between NDMI and NDVI for the summer months. This indicates that seasonal moisture impacts vegetation growth. &quot;) ## [1] &quot;There is a positive correlation between NDMI and NDVI for the summer months. This indicates that seasonal moisture impacts vegetation growth. &quot; 3.2 Question (2) What is the correlation between average NDSI (normalized snow index) for January - April and average NDVI for June-August? In other words, does the previous years snow cover influence vegetation growth for the following summer? f_ndsi&lt;-filter(full_long, data==&#39;ndsi&#39;)%&gt;% mutate(year=year(DateTime),month=month(DateTime))%&gt;% filter(month%in% c(1,2,3,4))%&gt;% group_by(year)%&gt;% summarise(mean_ndsi=mean(value)) f_ndvi&lt;-filter(full_long, data==&#39;ndvi&#39;)%&gt;% mutate(year=year(DateTime),month=month(DateTime))%&gt;% filter(month%in% c(7,8,9))%&gt;% group_by(year)%&gt;% summarise(mean_ndvi=mean(value)) all_year&lt;-inner_join(f_ndsi, f_ndvi, by=&#39;year&#39;) ggplot(all_year, aes(x=mean_ndsi, y=mean_ndvi))+ geom_point() + theme_few() + scale_color_few() + theme(legend.position=c(0.8,0.8)) print(&quot;There is a weak positive correlation between NSDI and NDVI. This indicates that the previous years&#39; snow cover influences the vegetation growth.&quot;) ## [1] &quot;There is a weak positive correlation between NSDI and NDVI. This indicates that the previous years&#39; snow cover influences the vegetation growth.&quot; 3.3 Question (3) How is the snow effect from question 2 different between pre- and post-burn and burned and unburned? ndsi3&lt;-filter(full_long, data==&#39;ndsi&#39;)%&gt;% mutate(year=year(DateTime),month=month(DateTime))%&gt;% filter(month%in% c(1,2,3,4))%&gt;% group_by(year,site)%&gt;% summarise(mean_ndsi=mean(value)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. ndvi3&lt;-filter(full_long, data==&#39;ndvi&#39;)%&gt;% mutate(year=year(DateTime),month=month(DateTime))%&gt;% filter(month%in% c(7,8,9))%&gt;% group_by(year,site)%&gt;% summarise(mean_ndvi=mean(value)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. all_year3&lt;-left_join(ndsi3, ndvi3) ## Joining, by = c(&quot;year&quot;, &quot;site&quot;) ggplot(all_year3, aes(x=mean_ndsi, y=mean_ndvi, color=site))+ geom_point() + theme_few() + scale_color_few() message(&quot;The burned sites (blue) are more impacted by the previous years snow than the unburned (orange) sites&quot;) ## The burned sites (blue) are more impacted by the previous years snow than the unburned (orange) sites 3.4 Question (4) What month is the greenest month on average? #plot it? monthlygreen&lt;-spread(full_long, key=&#39;data&#39;, value=&#39;value&#39;)%&gt;% mutate(month=month(DateTime))%&gt;% group_by( month)%&gt;% summarise(meanNdvi=mean(ndvi, na.rm=TRUE)) ggplot(monthlygreen, aes(x=month, y=meanNdvi))+ geom_point() + theme_few() + scale_color_few()+ scale_x_continuous(name=&quot;Month Number&quot;, limits=c(1, 12), breaks=c(2,4,6,8,10,12)) Q4&lt;-with(monthlygreen, month[which.max(meanNdvi)]) print(Q4) ## [1] 8 message(&quot;On average the greenest month is the &quot;, Q4, &quot;th month.&quot;) ## On average the greenest month is the 8th month. 3.5 Question (5) What month is the snowiest on average? snowy&lt;-spread(full_long, key=&#39;data&#39;, value=&#39;value&#39;)%&gt;% mutate(month=month(DateTime))%&gt;% group_by( month)%&gt;% summarise(meanNdsi=mean(ndsi, na.rm=TRUE)) ggplot(snowy, aes(x=month, y=meanNdsi))+ geom_point() + theme_few() + scale_color_few()+ scale_x_continuous(name=&quot;Month Number&quot;, limits=c(1, 12), breaks=c(2,4,6,8,10,12)) Q5&lt;-with(snowy, month[which.max(meanNdsi)]) print(Q5) ## [1] 1 message(&quot;On average the snowiest month is the &quot;, Q5, &quot;st month.&quot;) ## On average the snowiest month is the 1st month. "],["functions-and-iterations.html", "Chapter 4 Functions and Iterations 4.1 Loop to read in data 4.2 Read in Function 4.3 Map Function 4.4 Plotting data 4.5 Function to create multiple plots 4.6 Bonus", " Chapter 4 Functions and Iterations Learning to quickly go through and pull data out of a dataset using functions and iterations to avoid repeatitive code. library(rvest) site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; #Read the web url webpage &lt;- read_html(site_url) #Extract only weblinks and then the URLs! links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) message(links) ## https://snowstudies.org/wp-content/uploads/2022/02/SBB_SASP_Forcing_Data.txthttps://snowstudies.org/wp-content/uploads/2022/02/SBB_SBSP_Forcing_Data.txt 4.1 Loop to read in data Download the meteorological data. Use the download_file and str_split_fixed commands to download the data and save it in your data folder. You can use a for loop or a map function. splits &lt;- str_split_fixed(links,&#39;/&#39;,8) #Keep only the 8th column dataset &lt;- splits[,8] #generate a file list for where the data goes file_names &lt;- paste0(&#39;data/&#39;,dataset) for(i in 1:2){ download.file(links[i],destfile=file_names[i]) } downloaded &lt;- file.exists(file_names) list.dirs(path=&#39;3_snow_functions_iteration/data&#39;) ## character(0) 4.2 Read in Function Write a custom function to read in the data and append a site column to the data. # this code grabs the variable names from the metadata pdf file library(pdftools) ## Using poppler version 22.02.0 headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) headers ## [1] &quot;year&quot; ## [2] &quot;month&quot; ## [3] &quot;day&quot; ## [4] &quot;hour&quot; ## [5] &quot;minute&quot; ## [6] &quot;second&quot; ## [7] &quot;precip [kg m-2 s-1]&quot; ## [8] &quot;sw down [W m-2]&quot; ## [9] &quot;lw down [W m-2]&quot; ## [10] &quot;air temp [K]&quot; ## [11] &quot;windspeed [m s-1]&quot; ## [12] &quot;relative humidity [%]&quot; ## [13] &quot;pressure [Pa]&quot; ## [14] &quot;specific humidity [g g-1]&quot; ## [15] &quot;calculated dewpoint temperature [K]&quot; ## [16] &quot;precip, WMO-corrected [kg m-2 s-1]&quot; ## [17] &quot;air temp, corrected with Kent et al. (1993) [K]&quot; ## [18] &quot;air temp, corrected with Anderson and Baumgartner (1998)[K]&quot; ## [19] &quot;air temp, corrected with Nakamura and Mahrt (2005) [K]&quot; ## [20] &quot;air temp, corrected with Huwald et al. (2009) [K]&quot; ## [21] &quot;qc code precip&quot; ## [22] &quot;qc code sw down&quot; ## [23] &quot;qc code lw down&quot; ## [24] &quot;qc code air temp&quot; ## [25] &quot;qc code wind speed&quot; ## [26] &quot;qc code relhum&quot; #function to read in 1 data file # #file=file_names[1] reader&lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2]%&gt;% gsub(&#39;_Forcing_Data.txt&#39;,&#39;&#39;,.) df&lt;-read_fwf(file)%&gt;% select(c(1:11)) names(df)&lt;-headers[1:11] df&lt;-df%&gt;% mutate(site=name) } view(reader(file_names[1])) ## Rows: 69168 Columns: 19 ## -- Column specification -------------------------------------------------------- ## ## chr (2): X12, X14 ## dbl (17): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X13, X15, X16, X17, ... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. 4.3 Map Function Use the map function to read in both meteorological files. Display a summary of your tibble. met_files&lt;- map_dfr(file_names, reader) ## Rows: 69168 Columns: 19 ## -- Column specification -------------------------------------------------------- ## ## chr (2): X12, X14 ## dbl (17): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X13, X15, X16, X17, ... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## Rows: 69168 Columns: 19 ## -- Column specification -------------------------------------------------------- ## ## chr (2): X12, X14 ## dbl (17): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X13, X15, X16, X17, ... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. summary(met_files) ## year month day hour minute ## Min. :2003 Min. : 1.000 Min. : 1.00 Min. : 0.00 Min. :0 ## 1st Qu.:2005 1st Qu.: 3.000 1st Qu.: 8.00 1st Qu.: 5.75 1st Qu.:0 ## Median :2007 Median : 6.000 Median :16.00 Median :11.50 Median :0 ## Mean :2007 Mean : 6.472 Mean :15.76 Mean :11.50 Mean :0 ## 3rd Qu.:2009 3rd Qu.: 9.000 3rd Qu.:23.00 3rd Qu.:17.25 3rd Qu.:0 ## Max. :2011 Max. :12.000 Max. :31.00 Max. :23.00 Max. :0 ## second precip [kg m-2 s-1] sw down [W m-2] lw down [W m-2] ## Min. :0 Min. :0.000e+00 Min. :-9999.000 Min. :-9999.0 ## 1st Qu.:0 1st Qu.:0.000e+00 1st Qu.: -3.510 1st Qu.: 173.4 ## Median :0 Median :0.000e+00 Median : -0.344 Median : 231.4 ## Mean :0 Mean :3.838e-05 Mean :-1351.008 Mean :-1325.7 ## 3rd Qu.:0 3rd Qu.:0.000e+00 3rd Qu.: 294.900 3rd Qu.: 272.2 ## Max. :0 Max. :6.111e-03 Max. : 1341.000 Max. : 365.8 ## air temp [K] windspeed [m s-1] site ## Min. :242.1 Min. :-9999.000 Length:138336 ## 1st Qu.:265.8 1st Qu.: 0.852 Class :character ## Median :272.6 Median : 1.548 Mode :character ## Mean :272.6 Mean : -790.054 ## 3rd Qu.:279.7 3rd Qu.: 3.087 ## Max. :295.8 Max. : 317.300 4.4 Plotting data Make a line plot of mean temp by year by site (using the air temp [K] variable). Is there anything suspicious in the plot? Adjust your filtering if needed. temperature&lt;-met_files%&gt;% group_by(year, site)%&gt;% summarize(meanT = mean(`air temp [K]`)) ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. ggplot(temperature, aes(x=year, y=meanT, color=site))+ geom_line()+ ggthemes::theme_few() message(&quot;Site SBB_SASP has a higher yearly mean temperature than site SBB_SBSP for all years in the dataset. There is a big jump in temperature from the first year to the following years. Further inspection (in Q6) is needed to determine the suspicious jump in data.&quot;) ## Site SBB_SASP has a higher yearly mean temperature than site SBB_SBSP for all years in the dataset. There is a big jump in temperature from the first year to the following years. Further inspection (in Q6) is needed to determine the suspicious jump in data. 4.5 Function to create multiple plots Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot? Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html loopy&lt;-function(data, xyear){ #y&lt;-as.vector(unique(data[c(&quot;year&quot;)])) met&lt;-data%&gt;%group_by(year, month , site)%&gt;% summarize(meanT=mean(`air temp [K]`))%&gt;% dplyr::filter(year==xyear) print(ggplot(met,aes(x=month, y=meanT, color=site))+ geom_line()+ facet_wrap(xyear))} for (i in 2005:2010){ loopy(met_files, i) } ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the ## `.groups` argument. message(&quot;From 2005 to 2010 the monthly average temperatures at the Senator Beck Study Plot are never warmer than the Snow Angel Study Plot&quot;) ## From 2005 to 2010 the monthly average temperatures at the Senator Beck Study Plot are never warmer than the Snow Angel Study Plot 4.6 Bonus Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. #coloring each site will not work with duplicate site data met_files$second&lt;-as.Date(with(met_files,paste(month,day,sep=&quot;-&quot;)),&quot;%m-%d&quot;)%&gt;% format(., &quot;%j&quot;) pre&lt;-group_by(met_files,second)%&gt;% summarize(meanPre = mean(`precip [kg m-2 s-1]`)) names(pre)=c(&#39;Julian_Day&#39;, &#39;Mean_Precip&#39;) ggplot(pre, aes(x=Julian_Day,y=Mean_Precip))+ geom_point()+ ggthemes::theme_few() Bonus #2: Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. Ploopy&lt;-function(data, xyear){ #y&lt;-as.vector(unique(data[c(&quot;year&quot;)])) met&lt;-data%&gt;%group_by(year, second , site)%&gt;% summarize(meanP=mean(`precip [kg m-2 s-1]`))%&gt;% dplyr::filter(year==xyear) colnames(met)[2]=&#39;Julian_Day&#39; print(ggplot(met,aes(x=Julian_Day, y=meanP, color=site))+ geom_point()+ facet_wrap(xyear))} for (i in 2003:2010){ Ploopy(met_files, i) } ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. ## `summarise()` has grouped output by &#39;year&#39;, &#39;second&#39;. You can override using ## the `.groups` argument. "],["regressions.html", "Chapter 5 Regressions 5.1 Weather Data Analysis 5.2 Temperature trends 5.3 Multiple regression  5.4 Download NASS corn yield data 5.5 Question 1a: 5.6 Question 2 5.7 Question 3 5.8 Question 4 5.9 Question 5", " Chapter 5 Regressions Using regressions to make assumptions about data trends 5.1 Weather Data Analysis Load the PRISM daily maximum temperatures # daily max temperature # dimensions: counties x days x years prism &lt;- readMat(&quot;data/prismiowa.mat&quot;) # look at county #1 t_1981_c1 &lt;- prism$tmaxdaily.iowa[1,,1] t_1981_c1[366] ## [1] NaN # assign dimension names to tmax matrix dimnames(prism$tmaxdaily.iowa) &lt;- list(prism$COUNTYFP, 1:366, prism$years) # converted 3d matrix into a data frame tmaxdf &lt;- as.data.frame.table(prism$tmaxdaily.iowa) # relabel the columns colnames(tmaxdf) &lt;- c(&quot;countyfp&quot;,&quot;doy&quot;,&quot;year&quot;,&quot;tmax&quot;) tmaxdf &lt;- tibble(tmaxdf) 5.2 Temperature trends Summer temperature trends: Winneshiek County tmaxdf$doy &lt;- as.numeric(tmaxdf$doy) tmaxdf$year &lt;- as.numeric(as.character(tmaxdf$year)) winnesummer &lt;- tmaxdf %&gt;% filter(countyfp==191 &amp; doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) ggplot(winnesummer, mapping = aes(x = year, y = meantmax)) + geom_point() + theme_bw() + labs(x = &quot;year&quot;, y = &quot;Tmax (°C)&quot;) + geom_smooth(method = lm) ## `geom_smooth()` using formula &#39;y ~ x&#39; lm_summertmax &lt;- lm(meantmax ~ year, winnesummer) #summary(lm_summertmax) Winter Temperatures - Winneshiek County winnewinter &lt;- tmaxdf %&gt;% filter(countyfp==191 &amp; (doy &lt;= 59 | doy &gt;= 335) &amp; !is.na(tmax)) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) ggplot(winnewinter, mapping = aes(x = year, y = meantmax)) + geom_point() + theme_bw() + labs(x = &quot;year&quot;, y = &quot;Tmax (°C)&quot;) + geom_smooth(method = lm) ## `geom_smooth()` using formula &#39;y ~ x&#39; lm_wintertmax &lt;- lm(meantmax ~ year, winnewinter) #summary(lm_wintertmax) 5.3 Multiple regression  Quadratic time trend winnewinter$yearsq &lt;- winnewinter$year^2 lm_wintertmaxquad &lt;- lm(meantmax ~ year + yearsq, winnewinter) summary(lm_wintertmaxquad) ## ## Call: ## lm(formula = meantmax ~ year + yearsq, data = winnewinter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.3539 -1.2985 -0.2813 1.4055 4.2620 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.086e+04 1.238e+04 -0.877 0.386 ## year 1.085e+01 1.239e+01 0.876 0.387 ## yearsq -2.710e-03 3.097e-03 -0.875 0.388 ## ## Residual standard error: 2.051 on 35 degrees of freedom ## Multiple R-squared: 0.02694, Adjusted R-squared: -0.02867 ## F-statistic: 0.4845 on 2 and 35 DF, p-value: 0.6201 winnewinter$fitted &lt;- lm_wintertmaxquad$fitted.values ggplot(winnewinter) + geom_point(mapping = aes(x = year, y = meantmax)) + geom_line(mapping = aes(x = year, y = fitted)) + theme_bw() + labs(x = &quot;year&quot;, y = &quot;tmax&quot;) 5.4 Download NASS corn yield data USDA NASS data download # set our API key with NASS nassqs_auth(key = &quot;2FCF525A-8D93-3647-9216-07E60D61705D&quot;) # parameters to query on params &lt;- list(commodity_desc = &quot;CORN&quot;, util_practice_desc = &quot;GRAIN&quot;, prodn_practice_desc = &quot;ALL PRODUCTION PRACTICES&quot;, year__GE = 1981, state_alpha = &quot;IA&quot;) # download cornyieldsall &lt;- nassqs_yields(params) cornyieldsall$county_ansi &lt;- as.numeric(cornyieldsall$county_ansi) cornyieldsall$yield &lt;- as.numeric(cornyieldsall$Value) # clean and filter this dataset cornyields &lt;- select(cornyieldsall, county_ansi, county_name,county_code, yield, year) %&gt;% filter(!is.na(county_ansi) &amp; !is.na(yield)) cornyields &lt;- tibble(cornyields) 5.5 Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend? winne&lt;- cornyieldsall%&gt;% filter(county_name==&#39;WINNESHIEK&#39;) Winne_CY &lt;- tibble(winne) Winne_CY$yield &lt;- as.numeric(Winne_CY$yield) ggplot(Winne_CY, mapping = aes(x=year, y=yield))+ geom_point()+ theme_bw()+ geom_smooth(method = lm)+ xlab(&quot;Year&quot;)+ ylab(&quot;Yield&quot;)+ ggtitle(&quot;Corn Yields in Winneshiek County&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; message(&quot;There is an increasing linear trend between year and yield.&quot;) ## There is an increasing linear trend between year and yield. 5.5.1 Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? Winne_CY$year &lt;- as.numeric(Winne_CY$year) Winne_CY$yearsq &lt;- Winne_CY$year^2 lm_winnequad &lt;- lm(yield ~ year + yearsq, Winne_CY) summary(lm_winnequad) ## ## Call: ## lm(formula = yield ~ year + yearsq, data = Winne_CY) ## ## Residuals: ## Min 1Q Median 3Q Max ## -51.384 -3.115 1.388 9.743 25.324 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.583e+04 8.580e+04 0.301 0.765 ## year -2.812e+01 8.576e+01 -0.328 0.745 ## yearsq 7.641e-03 2.143e-02 0.357 0.723 ## ## Residual standard error: 17.17 on 38 degrees of freedom ## Multiple R-squared: 0.7559, Adjusted R-squared: 0.7431 ## F-statistic: 58.84 on 2 and 38 DF, p-value: 2.311e-12 Winne_CY$fitted &lt;- lm_winnequad$fitted.values ggplot(Winne_CY) + geom_point(mapping = aes(x = year, y = yield)) + geom_line(mapping = aes(x = year, y = fitted)) + theme_bw() + labs(x = &quot;year&quot;, y = &quot;yield&quot;)+ ggtitle(&quot;Winneshiek County Time Trend&quot;) message(&quot;There does not seem to be evidence of slowing yield in Winneshiek County because there is a positive quadratic relationship. &quot;) ## There does not seem to be evidence of slowing yield in Winneshiek County because there is a positive quadratic relationship. 5.6 Question 2 Time Series: Lets analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results. q2&lt;-inner_join(winnesummer, Winne_CY) ## Joining, by = &quot;year&quot; ggplot(q2,aes(x=meantmax, y=yield))+ theme_bw()+ geom_point()+ labs(x=&quot;Mean Max Temperature (°C)&quot;, y=&quot;Corn Yield&quot;)+ ggtitle(&quot;Temperature and Yield for Winneshiek County&quot;) q2$tmp2&lt;-q2$meantmax^2 lm_quad &lt;- lm(yield ~ meantmax + tmp2, q2) summary(lm_quad) ## ## Call: ## lm(formula = yield ~ meantmax + tmp2, data = q2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -56.587 -22.262 -0.982 22.409 52.798 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4223.604 1446.639 -2.920 0.00609 ** ## meantmax 328.918 107.068 3.072 0.00410 ** ## tmp2 -6.173 1.979 -3.119 0.00362 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.5 on 35 degrees of freedom ## Multiple R-squared: 0.2417, Adjusted R-squared: 0.1984 ## F-statistic: 5.579 on 2 and 35 DF, p-value: 0.007887 q2$fittedq &lt;- lm_quad$fitted.values ggplot(q2)+ geom_point(mapping = aes(x=meantmax, y=yield))+ geom_line(mapping = aes(x=meantmax, y=fittedq))+ theme_bw()+ labs(x=&quot;Mean Max Temperature (°C)&quot;, y=&quot;Corn Yield&quot;)+ ggtitle(&quot;Trend of Temperature and Yield for Winneshiek County&quot;) message(&#39;Adding a model of Tmax^2 is helpful to interperte the trends of temperature and its effects on corn yield. From this graph you can see as temperature increases yield does as well until a threshold is reached and yield begins to decrease as temperature gets hotter.&#39; ) ## Adding a model of Tmax^2 is helpful to interperte the trends of temperature and its effects on corn yield. From this graph you can see as temperature increases yield does as well until a threshold is reached and yield begins to decrease as temperature gets hotter. 5.7 Question 3 Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results. colnames(cornyields)[1]=&quot;countyfp&quot; cornyields$countyfp&lt;- as.numeric(cornyields$countyfp) tmaxdf$countyfp&lt;- as.numeric(tmaxdf$countyfp) yield18&lt;- cornyields%&gt;% filter(year==&#39;2018&#39;) temp18&lt;-tmaxdf%&gt;% filter(year==&#39;2018&#39;) jd18&lt;-inner_join(yield18, temp18, by =&quot;countyfp&quot;)%&gt;% filter(!is.na(tmax))%&gt;% group_by(countyfp, yield)%&gt;% summarise(meanTmax=mean(tmax)) ## `summarise()` has grouped output by &#39;countyfp&#39;. You can override using the ## `.groups` argument. ggplot(mapping = aes(x=jd18$meanTmax, y=jd18$yield))+ geom_point()+ ggtitle(&quot;2018 Temperature and Yield Analysis&quot;)+ theme_bw()+ labs(x=&quot;Mean Max Temperature (°C)&quot;, y=&quot;Corn Yield&quot;)+ geom_smooth(method = lm) ## `geom_smooth()` using formula &#39;y ~ x&#39; message(&#39;There does not seem to be much of a trend between temperature and corn yield over all of the counties in 2018. When a linear model if fitted to the data you can see a slight decreasing trend in temperature vs yield. &#39;) ## There does not seem to be much of a trend between temperature and corn yield over all of the counties in 2018. When a linear model if fitted to the data you can see a slight decreasing trend in temperature vs yield. 5.8 Question 4 Panel: One way to leverage multiple time series is to group all data into what is called a panel regression. Convert the county ID code (countyfp or county_ansi) into factor using as.factor, then include this variable in a regression using all counties yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model. summer &lt;- tmaxdf %&gt;% filter(doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) cornyields$year &lt;- as.numeric(cornyields$year) combo&lt;- inner_join(cornyields, summer, by=&#39;year&#39;) combo$fac&lt;- as.factor(combo$countyfp) combo$temp2&lt;-combo$meantmax^2 lm_combo&lt;-lm(yield~meantmax+temp2+year+fac, combo) summary(lm_combo) ## ## Call: ## lm(formula = yield ~ meantmax + temp2 + year + fac, data = combo) ## ## Residuals: ## Min 1Q Median 3Q Max ## -90.667 -9.604 1.444 13.250 48.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.787e+03 1.217e+02 -47.548 &lt; 2e-16 *** ## meantmax 1.154e+02 8.252e+00 13.989 &lt; 2e-16 *** ## temp2 -2.172e+00 1.469e-01 -14.794 &lt; 2e-16 *** ## year 2.199e+00 2.972e-02 73.980 &lt; 2e-16 *** ## fac3 -4.363e+00 4.495e+00 -0.971 0.331814 ## fac5 1.088e+01 4.495e+00 2.420 0.015567 * ## fac7 -1.902e+01 4.526e+00 -4.202 2.71e-05 *** ## fac9 8.829e+00 4.495e+00 1.964 0.049603 * ## fac11 1.246e+01 4.495e+00 2.772 0.005602 ** ## fac13 1.407e+01 4.495e+00 3.130 0.001761 ** ## fac15 1.844e+01 4.495e+00 4.102 4.19e-05 *** ## fac17 1.871e+01 4.495e+00 4.162 3.22e-05 *** ## fac19 1.517e+01 4.495e+00 3.374 0.000749 *** ## fac21 1.518e+01 4.495e+00 3.377 0.000740 *** ## fac23 1.544e+01 4.495e+00 3.434 0.000601 *** ## fac25 1.612e+01 4.495e+00 3.586 0.000341 *** ## fac27 1.398e+01 4.495e+00 3.111 0.001880 ** ## fac29 6.453e+00 4.495e+00 1.435 0.151258 ## fac31 2.040e+01 4.495e+00 4.538 5.86e-06 *** ## fac33 1.239e+01 4.495e+00 2.757 0.005858 ** ## fac35 1.935e+01 4.495e+00 4.304 1.72e-05 *** ## fac37 1.023e+01 4.495e+00 2.277 0.022866 * ## fac39 -2.427e+01 4.526e+00 -5.362 8.73e-08 *** ## fac41 1.341e+01 4.495e+00 2.984 0.002866 ** ## fac43 1.654e+01 4.495e+00 3.680 0.000236 *** ## fac45 1.553e+01 4.495e+00 3.456 0.000555 *** ## fac47 1.133e+01 4.495e+00 2.521 0.011753 * ## fac49 1.189e+01 4.495e+00 2.646 0.008180 ** ## fac51 -1.859e+01 4.526e+00 -4.108 4.09e-05 *** ## fac53 -1.720e+01 4.526e+00 -3.801 0.000147 *** ## fac55 1.704e+01 4.495e+00 3.790 0.000153 *** ## fac57 9.116e+00 4.495e+00 2.028 0.042650 * ## fac59 1.033e+01 4.495e+00 2.298 0.021635 * ## fac61 1.726e+01 4.495e+00 3.838 0.000126 *** ## fac63 1.533e+01 4.495e+00 3.410 0.000657 *** ## fac65 1.538e+01 4.495e+00 3.421 0.000632 *** ## fac67 1.219e+01 4.495e+00 2.713 0.006704 ** ## fac69 1.824e+01 4.495e+00 4.057 5.08e-05 *** ## fac71 4.174e+00 4.495e+00 0.928 0.353237 ## fac73 1.659e+01 4.495e+00 3.692 0.000226 *** ## fac75 1.816e+01 4.495e+00 4.040 5.45e-05 *** ## fac77 4.829e+00 4.495e+00 1.074 0.282799 ## fac79 1.814e+01 4.495e+00 4.035 5.58e-05 *** ## fac81 1.666e+01 4.495e+00 3.706 0.000214 *** ## fac83 1.938e+01 4.495e+00 4.312 1.66e-05 *** ## fac85 6.074e+00 4.495e+00 1.351 0.176745 ## fac87 3.134e+00 4.495e+00 0.697 0.485714 ## fac89 9.113e+00 4.495e+00 2.027 0.042710 * ## fac91 1.740e+01 4.495e+00 3.871 0.000110 *** ## fac93 1.729e+01 4.495e+00 3.846 0.000122 *** ## fac95 9.826e+00 4.495e+00 2.186 0.028887 * ## fac97 5.045e+00 4.495e+00 1.122 0.261845 ## fac99 1.697e+01 4.495e+00 3.775 0.000162 *** ## fac101 -5.500e+00 4.495e+00 -1.223 0.221224 ## fac103 7.003e+00 4.495e+00 1.558 0.119378 ## fac105 1.369e+01 4.495e+00 3.045 0.002346 ** ## fac107 1.571e+00 4.495e+00 0.349 0.726746 ## fac109 1.997e+01 4.495e+00 4.441 9.20e-06 *** ## fac111 -3.897e+00 4.495e+00 -0.867 0.386010 ## fac113 1.196e+01 4.495e+00 2.660 0.007847 ** ## fac115 4.632e+00 4.495e+00 1.030 0.302934 ## fac117 -2.184e+01 4.557e+00 -4.793 1.71e-06 *** ## fac119 1.411e+01 4.495e+00 3.139 0.001709 ** ## fac121 -1.661e+00 4.495e+00 -0.369 0.711860 ## fac123 7.953e+00 4.495e+00 1.769 0.076964 . ## fac125 1.505e+00 4.495e+00 0.335 0.737758 ## fac127 1.995e+01 4.495e+00 4.438 9.35e-06 *** ## fac129 3.948e+00 4.557e+00 0.866 0.386439 ## fac131 1.537e+01 4.495e+00 3.418 0.000637 *** ## fac133 -1.079e+00 4.495e+00 -0.240 0.810332 ## fac135 -1.590e+01 4.526e+00 -3.513 0.000448 *** ## fac137 2.805e+00 4.495e+00 0.624 0.532642 ## fac139 8.576e+00 4.495e+00 1.908 0.056492 . ## fac141 2.073e+01 4.495e+00 4.612 4.12e-06 *** ## fac143 1.629e+01 4.495e+00 3.623 0.000295 *** ## fac145 -3.671e+00 4.495e+00 -0.817 0.414190 ## fac147 1.427e+01 4.495e+00 3.175 0.001510 ** ## fac149 1.027e+01 4.495e+00 2.284 0.022449 * ## fac151 1.764e+01 4.495e+00 3.924 8.87e-05 *** ## fac153 1.427e+01 4.495e+00 3.175 0.001510 ** ## fac155 1.022e+01 4.526e+00 2.259 0.023966 * ## fac157 1.257e+01 4.495e+00 2.796 0.005203 ** ## fac159 -2.102e+01 4.495e+00 -4.676 3.04e-06 *** ## fac161 1.519e+01 4.495e+00 3.380 0.000734 *** ## fac163 2.032e+01 4.495e+00 4.520 6.37e-06 *** ## fac165 1.143e+01 4.495e+00 2.542 0.011069 * ## fac167 1.963e+01 4.495e+00 4.366 1.30e-05 *** ## fac169 1.662e+01 4.495e+00 3.697 0.000222 *** ## fac171 1.516e+01 4.495e+00 3.371 0.000756 *** ## fac173 -1.572e+01 4.526e+00 -3.473 0.000521 *** ## fac175 -1.095e+01 4.526e+00 -2.420 0.015579 * ## fac177 -1.460e+01 4.495e+00 -3.247 0.001176 ** ## fac179 -5.989e+00 4.526e+00 -1.323 0.185792 ## fac181 -2.482e+00 4.495e+00 -0.552 0.580959 ## fac183 8.547e+00 4.495e+00 1.901 0.057330 . ## fac185 -2.161e+01 4.526e+00 -4.775 1.87e-06 *** ## fac187 2.020e+01 4.495e+00 4.493 7.24e-06 *** ## fac189 1.633e+01 4.495e+00 3.634 0.000283 *** ## fac191 1.291e+01 4.495e+00 2.871 0.004118 ** ## fac193 4.774e+00 4.495e+00 1.062 0.288343 ## fac195 1.419e+01 4.495e+00 3.156 0.001610 ** ## fac197 1.838e+01 4.495e+00 4.088 4.44e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 19.59 on 3646 degrees of freedom ## Multiple R-squared: 0.6977, Adjusted R-squared: 0.6893 ## F-statistic: 83.3 on 101 and 3646 DF, p-value: &lt; 2.2e-16 combo$fitted&lt;-lm_combo$fitted.values ggplot()+ geom_point(combo, mapping=aes(x=fitted, y=yield))+ geom_smooth(combo, mapping=aes(x=fitted, y=yield),method = lm)+ theme_bw()+ labs(x=&#39;Predicted Yield&#39;, y=&#39;Actual Yield&#39;)+ ggtitle(&quot;Actual Yield and fitted yield&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; message(&#39;The model fits yield based on multiple variables including mean max temp, temperature squared, each county, and each year. The coefficients for temperature is positive but the coefficient for temp^2 is negative. The graph shows how well the modeled predicts values for yield, it is not quite a one to one relationship but there is a linear trend.&#39;) ## The model fits yield based on multiple variables including mean max temp, temperature squared, each county, and each year. The coefficients for temperature is positive but the coefficient for temp^2 is negative. The graph shows how well the modeled predicts values for yield, it is not quite a one to one relationship but there is a linear trend. 5.9 Question 5 Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years. "],["machine-learning.html", "Chapter 6 Machine Learning 6.1 Model development 6.2 Chl-a model 6.3 TSS Model", " Chapter 6 Machine Learning Using machine learning to fine tune a model to get the lowest error. A friend told me today about a term called Grad student descent which is a play on words with the term gradient descent, an extremely common tool used to tune hyperparameters (and parameters) for machine learning models. Grad student descent then is when that method is simply having grad students search a parameter space manually in part to improve the model, and in part to learn how these algorithms work. Today we are trying to predict the concentrations of either chlorophyll a (CHLA) or total suspended sediment (TSS) in the Loire River France using satellite imagery. The grab sample data (someone grabbing water from a stream for analysis), comes from the French electricity agency who collects this data to meet their water quality standards. Basically the core idea here is that water color as captured in an image tells you something about what is in the water. If its green and bright (lots of light reflected from the water), then it may have a lot of algae (Chlorophyll a is a proxy for algal biomass). If its tan and bright, it may have lots of sediment. If its dark and blue its clear! This color information is captured in bands like red, blue, green etc from the Landsat series of satellites, which have collected data over the world since the late 70s. For this analysis we are only using Landsat 5,7, and 8, so the data goes back to 1984. 6.1 Model development wq_sr &lt;- read_csv(&#39;data/wq_sr.csv&#39;) %&gt;% mutate(year = year(date)) ## Rows: 777 Columns: 109 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## chr (6): site_name, geometry, LS_ID, sat, season, hexcolor ## dbl (100): site_no, TSS, PheoP, CHLA, lat, long, split_ID, Cloud_Cover, azi... ## dttm (1): date_time ## date (1): date ## time (1): time ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. This is the fiddly bit. The goal? Tune hyperparameters to get the lowest RMSE and the best Measured/Predicted fit (points close to the red line). # A vector that contains all the columns I want to keep. predictors &lt;- c(&quot;azimuth&quot;, &quot;blue&quot;,&quot;green&quot;, &quot;nir&quot; ,&quot;red&quot;, &quot;swir1&quot;,&quot;swir2&quot;,&quot;zenith&quot; , &quot;NR&quot; ,&quot;BR&quot; ,&quot;GR&quot; , &quot;SR&quot; , &quot;BG&quot; , &quot;BN&quot;, &quot;BS&quot; ,&quot;GS&quot; ,&quot;GN&quot; , &quot;ndvi&quot;, &quot;ndwi&quot;, &#39;fai&#39;, &quot;hillshade&quot;, &quot;hue&quot;, &quot;bright_tot&quot;, &quot;bright&quot;) booster &lt;- function(df = wq_sr,pred=&#39;CHLA&#39;,title=&#39;Chlorophyll a&#39;, features = predictors){ non_nas &lt;- (!is.na(df[,pred])) #remove nas df = df[non_nas,] #Sample 60% of the data. train &lt;- df %&gt;% sample_frac(0.6) #Keep only data that is not in train #How could we make this safer (spatiotemporal robustness) test &lt;- df %&gt;% anti_join(.,train,by=&#39;index&#39;) # Actual boosting model ag_mod &lt;- xgboost(data=train %&gt;% dplyr::select(features) %&gt;% as.matrix(.), label = train %&gt;% pull(pred) %&gt;% log10(.), nthread=4, max_depth=4, eta=0.1, gamma = 0.1, nrounds=300, subsample = 0.5, #best_par[&#39;subsample&#39;], # 0.5, colsample_bytree = 0.5, #0.5, min_child_weight = 1, lambda = 3, print_every_n = 100) #Tune ntree, k, numcut, bands that you use, etc... #apply predictions. test &lt;- test %&gt;% mutate(bpred= 10^predict(ag_mod,test %&gt;% dplyr::select(features) %&gt;% as.matrix(.))) #Optional for log #test[,pred] = 10^test[,pred] #Remove NAs test &lt;- test %&gt;% filter(!is.na(pred)) %&gt;% as.data.frame() error &lt;- tibble(rmse=Metrics::rmse(test$bpred,test[,pred]), mdae=Metrics::mdae(test$bpred,test[,pred]), mape=Metrics::mape(test$bpred,test[,pred]), bias=Metrics::bias(test$bpred,test[,pred])) g1 &lt;- ggplot(test, aes_string(x=pred,y=&#39;bpred&#39;,color=&#39;year&#39;)) + geom_point() + geom_abline(intercept=0,slope=1,color=&#39;red&#39;) + labs(x=&#39;Measured&#39;,y=&#39;Predicted&#39;) + theme_few() + scale_color_viridis_c() + scale_x_log10(breaks = trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + scale_y_log10(breaks = trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + ggtitle(title) # returns a list of the plot (g1), the error metric (error), and the # model (ag_mod) return(list(g1,error,ag_mod)) } 6.2 Chl-a model set.seed(2020526) ## Makes the work reproducible, but you can hack this! chl_boost &lt;- booster(df = wq_sr) ## Note: Using an external vector in selections is ambiguous. ## i Use `all_of(features)` instead of `features` to silence this message. ## i See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This message is displayed once per session. ## [1] train-rmse:0.806420 ## [101] train-rmse:0.192442 ## [201] train-rmse:0.136304 ## [300] train-rmse:0.123537 6.2.1 Chl-a Model Measured/Predicted Plot chl_boost[[1]] chl_boost[[2]] ## # A tibble: 1 x 4 ## rmse mdae mape bias ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 24.3 6.16 1.12 -4.75 6.3 TSS Model predictors &lt;- c(&quot;azimuth&quot;, &quot;blue&quot;,&quot;green&quot;, &quot;nir&quot; ,&quot;red&quot;, &quot;swir1&quot;,&quot;swir2&quot;,&quot;zenith&quot; , &quot;NR&quot; ,&quot;BR&quot; ,&quot;GR&quot; , &quot;SR&quot; , &quot;BG&quot; , &quot;BN&quot;, &quot;BS&quot; ,&quot;GS&quot; ,&quot;GN&quot; , &quot;ndvi&quot;, &quot;ndwi&quot;, &#39;fai&#39;, &quot;hillshade&quot;, &quot;hue&quot;, &quot;bright_tot&quot;, &quot;bright&quot;) boosted &lt;- function(df = wq_sr,pred=&#39;TSS&#39;,title=&#39;Total Suspended Solids&#39;, features = predictors){ non_nas &lt;- (!is.na(df[,pred])) #remove nas df = df[non_nas,] #Sample 60% of the data. train &lt;- df %&gt;% sample_frac(0.6) #Keep only data that is not in train #How could we make this safer (spatiotemporal robustness) test &lt;- df %&gt;% anti_join(.,train,by=&#39;index&#39;) # Actual boosting model ag_mod &lt;- xgboost(data=train %&gt;% dplyr::select(features) %&gt;% as.matrix(.), label = train %&gt;% pull(pred) %&gt;% log10(.), nthread=4, max_depth=4, eta=0.1, gamma = 0.1, nrounds=300, subsample = 0.5, #best_par[&#39;subsample&#39;], # 0.5, colsample_bytree = 0.5, #0.5, min_child_weight = 1, lambda = 3, #3 print_every_n = 100) #Tune ntree, k, numcut, bands that you use, etc... #apply predictions. test &lt;- test %&gt;% mutate(bpred= 10^predict(ag_mod,test %&gt;% dplyr::select(features) %&gt;% as.matrix(.))) #Optional for log #test[,pred] = 10^test[,pred] #Remove NAs test &lt;- test %&gt;% filter(!is.na(pred)) %&gt;% as.data.frame() error &lt;- tibble(rmse=Metrics::rmse(test$bpred,test[,pred]), mdae=Metrics::mdae(test$bpred,test[,pred]), mape=Metrics::mape(test$bpred,test[,pred]), bias=Metrics::bias(test$bpred,test[,pred])) g2 &lt;- ggplot(test, aes_string(x=pred,y=&#39;bpred&#39;,color=&#39;year&#39;)) + geom_point() + geom_abline(intercept=0,slope=1,color=&#39;red&#39;) + labs(x=&#39;Measured&#39;,y=&#39;Predicted&#39;) + theme_few() + scale_color_viridis_c() + scale_x_log10(breaks = trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + scale_y_log10(breaks = trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + ggtitle(title) return(list(g2,error,ag_mod)) } 6.3.1 TSS Evaluation set.seed(2020526) ## Makes the work reproducible, but you can hack this! tss_boost &lt;- boosted(df = wq_sr) ## [1] train-rmse:0.750469 ## [101] train-rmse:0.154017 ## [201] train-rmse:0.121745 ## [300] train-rmse:0.113153 tss_boost[[1]] tss_boost[[2]] ## # A tibble: 1 x 4 ## rmse mdae mape bias ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 90.4 5.05 0.648 5.30 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
