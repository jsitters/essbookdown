--- 
title: "ESS Final Project"
author: "Jan Sitterson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
editor_options: 
  chunk_output_type: console
---

# R Markdown



```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dataRetrieval)
library(dygraphs)
library(xts)
```


# Methods

The Poudre River at Lincoln Bridge is:

  - Downstream of only a little bit of urban stormwater

  - Near Odell Brewing CO
  
  - Near an open space area and the Poudre River Trail
  
  - **Downstream of many agricultral diversions**


## SiteDescription

![](https://waterdata.usgs.gov/nwisweb/local/state/co/text/pics/06752260big.jpg)


## Data Acquisition and Plotting tests

## Data Download


```{r downloader}

q <- readNWISdv(siteNumbers = '06752260',
                parameterCd = '00060',
                startDate = '2017-01-01',
                endDate = '2022-01-01') %>%
  rename(q = 'X_00060_00003')


```



## Static Data Plotter


```{r}

ggplot(q, aes(x = Date, y = q)) + 
  geom_line() + 
  ylab('Q (cfs)') + 
  ggtitle('Discharge in the Poudre River, Fort Collins')

```


## Interactive Data Plotter


```{r}

q_xts <- xts(q$q, order.by = q$Date)


dygraph(q_xts) %>%
  dyAxis("y", label = "Discharge (cfs)") 
```



# Assignment Prompt 


This assignment will be primarily about demonstrating some expertise in using
RMarkdown, since we will be using Rmds as the primary form of homework and 
assignments. With that in mind, your assignment for this homework is to:


1) Fork the example repository into your personal GitHub

2) Create an RStudio project from your Personal clone of the Repo. 

3) Create a table of contents that is floating, but displays three levels of
headers instead of two (by editing the content at the beginning of the document)

4) Make a version of the `dygraph` with points and lines by using rstudio's
dygraph [guide](https://rstudio.github.io/dygraphs/)

5) Writing a paragraph on the Poudre river with at least three hyperlinks,
**two bolded sections**, and one *italicized phrase*. The content of this paragraph
is not vital, but try to at least make it true and interesting, and, of course,
don't plagiarize. 

6) Knit that document, and then git commit and push to your personal GitHub.

7) Use the GitHub -> Settings -> Pages tab to create a website of your report.

8) Bonus, make the timestamp in the header dynamic. As in it only adds
todays date, not just a static date you enter. 

9) Bonus, create an "index_talk.Rmd" version of your document using the
`revealjs` package. Add link to your original report-style document. 



# Solution to Assignment 



## DyGraph example 
```{r}

dygraph(q_xts) %>% 
dyRangeSelector()
``` 
## Poudre Paragraph
The _Cache la Poudre_ is a snow melt fed watershed in Northern Colorado. Much of the Poudre is under limited human impact, with almost __half__ of the river designated as a [Wild and Scenic river](https://www.rivers.gov/wsr-act.php). The City of Fort Collins is concerned that [microplastics](https://oceanservice.noaa.gov/facts/microplastics.html) in freshwater environments could impact both __ecological__ and __human__ health since the Cache la Poudre River watershed is a main source of drinking and irrigation water for Northern Colorado. Utility managers are interested in finding out a way to remove microplastics through the WWTP as described in the research by [Ngo](https://www.sciencedirect.com/science/article/pii/S0269749119337169).


<!--chapter:end:index.Rmd-->

# Data Wrangle

```{r setup2, warning=F,message=F}
library(tidyverse)
library(tidyr)
library(ggthemes)
library(lubridate)

# Now that we have learned how to munge (manipulate) data
# and plot it, we will work on using these skills in new ways

knitr::opts_knit$set(root.dir='..')
```


```{r dataread, warning=F,message=F}
####-----Reading in Data and Stacking it ----- ####
#Reading in files
files <- list.files('data',full.names=T)
##'data' will work if not inline printing


#Read in individual data files
ndmi <- read_csv(files[1]) %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndmi')


ndsi <- read_csv(files[2]) %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndsi')

ndvi <- read_csv(files[3])%>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndvi')

# Stack as a tidy dataset
full_long <- rbind(ndvi,ndmi,ndsi) %>%
  gather(key='site',value='value',-DateTime,-data) %>%
  filter(!is.na(value))
##new word is called pivot_longer

```




## Question 1) 

What is the correlation between NDVI and NDMI? - here I want you to
convert the full_long dataset in to a wide dataset using the 
function "spread" and then make a plot that shows the correlation s a
function of if the site was burned or not (x axis should be ndmi)
You should exclude winter months and focus on summer months
```{r}

full_wide<-spread(full_long, key='data', value='value')%>%
  mutate(month=month(DateTime))%>%
  filter( month %in% c(5,6,7,8,9))

ggplot(full_wide, aes(x=ndmi, y=ndvi,color=site ))+
  geom_point(shape=1) + 
  theme_few() + 
  scale_color_few() + 
  theme(legend.position=c(0.8,0.8))
print("There is a positive correlation between NDMI and NDVI for the summer months. This indicates that seasonal moisture impacts vegetation growth. ")

```
## Question 2 

2) What is the correlation between average NDSI (normalized
 snow index) for January - April and average NDVI for June-August?
In other words, does the previous year's snow cover influence vegetation
 growth for the following summer?
```{r}

f_ndsi<-filter(full_long, data=='ndsi')%>%
  mutate(year=year(DateTime),month=month(DateTime))%>%
  filter(month%in% c(1,2,3,4))%>%
  group_by(year)%>%
  summarise(mean_ndsi=mean(value))

f_ndvi<-filter(full_long, data=='ndvi')%>%
  mutate(year=year(DateTime),month=month(DateTime))%>%
  filter(month%in% c(7,8,9))%>%
  group_by(year)%>%
  summarise(mean_ndvi=mean(value))

all_year<-inner_join(f_ndsi, f_ndvi, by='year')
  
ggplot(all_year, aes(x=mean_ndsi, y=mean_ndvi))+ 
  geom_point() + 
  theme_few() + 
  scale_color_few() + 
  theme(legend.position=c(0.8,0.8))
print("There is a weak positive correlation between NSDI and NDVI. This indicates that the previous years' snow cover influences the vegetation growth.")

```
## Q3

How is the snow effect from question 2 different between pre- and post-burn
and burned and unburned? 

```{r}
ndsi3<-filter(full_long, data=='ndsi')%>%
  mutate(year=year(DateTime),month=month(DateTime))%>%
  filter(month%in% c(1,2,3,4))%>%
  group_by(year,site)%>%
  summarise(mean_ndsi=mean(value))

ndvi3<-filter(full_long, data=='ndvi')%>%
  mutate(year=year(DateTime),month=month(DateTime))%>%
  filter(month%in% c(7,8,9))%>%
  group_by(year,site)%>%
  summarise(mean_ndvi=mean(value))

all_year3<-left_join(ndsi3, ndvi3)

ggplot(all_year3, aes(x=mean_ndsi, y=mean_ndvi, color=site))+ 
  geom_point() + 
  theme_few() + 
  scale_color_few()
message("The burned sites (blue) are more impacted by the previous years snow than the unburned (orange) sites")
```
## Question 4

What month is the greenest month on average? 

```{r}
#plot it?
monthlygreen<-spread(full_long, key='data', value='value')%>%
  mutate(month=month(DateTime))%>%
  group_by( month)%>%
  summarise(meanNdvi=mean(ndvi, na.rm=TRUE))

ggplot(monthlygreen, aes(x=month, y=meanNdvi))+ 
  geom_point() + 
  theme_few() + 
  scale_color_few()+ 
  scale_x_continuous(name="Month Number", limits=c(1, 12), breaks=c(2,4,6,8,10,12))

Q4<-with(monthlygreen, month[which.max(meanNdvi)])
print(Q4)
message("On average the greenest month is the ", Q4, "th month.")
```


## Question 5) 

What month is the snowiest on average?
```{r}
snowy<-spread(full_long, key='data', value='value')%>%
  mutate(month=month(DateTime))%>%
  group_by( month)%>%
  summarise(meanNdsi=mean(ndsi, na.rm=TRUE))

ggplot(snowy, aes(x=month, y=meanNdsi))+ 
  geom_point() + 
  theme_few() + 
  scale_color_few()+ 
  scale_x_continuous(name="Month Number", limits=c(1, 12), breaks=c(2,4,6,8,10,12))

Q5<-with(snowy, month[which.max(meanNdsi)])
print(Q5)
message("On average the snowiest month is the ", Q5, "st month.")
```

<!--chapter:end:02-Wrangle.Rmd-->

# Functions and Iterations
```{r setup3, include=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(readxl)

```

```{r}
library(rvest)
site_url <- 'https://snowstudies.org/archived-data/'
#Read the web url
webpage <- read_html(site_url)

#Extract only weblinks and then the URLs!
links <- webpage %>%
  html_nodes('a') %>%
  .[grepl('forcing',.)] %>%
  html_attr('href')
message(links)
```
2. Download the meteorological data. Use the `download_file` and `str_split_fixed` commands to download the data and save it in your data folder. You can use a for loop or a map function. 
```{r}
splits <- str_split_fixed(links,'/',8)
#Keep only the 8th column
dataset <- splits[,8] 
#generate a file list for where the data goes
file_names <- paste0('data/',dataset)
for(i in 1:3){
  download.file(links[i],destfile=file_names[i])
}
downloaded <- file.exists(file_names)
list.dirs(path='3_snow_functions_iteration/data')


```
3. Write a custom function to read in the data and append a site column to the data. 

```{r}

# this code grabs the variable names from the metadata pdf file
library(pdftools)
headers <- pdf_text('https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf') %>%
  readr::read_lines(.) %>%
  trimws(.) %>%
  str_split_fixed(.,'\\.',2) %>%
  .[,2] %>%
  .[1:26] %>%
  str_trim(side = "left")
headers
#function to read in 1 data file
# 
#file=file_names[1]
reader<- function(file){
  name = str_split_fixed(file,'/',2)[,2]%>%
  gsub('_Forcing_Data.txt','',.)
  df<-read_fwf(file)%>%
    select(c(1:11))
    names(df)<-headers[1:11]
    df<-df%>%
      mutate(site=name)
}
view(reader(file_names[1]))


```

4. Use the `map` function to read in both meteorological files. Display a summary of your tibble.
```{r}

met_files<- map_dfr(file_names, reader)
summary(met_files)

```
5. Make a line plot of mean temp by year by site (using the `air temp [K]` variable). Is there anything suspicious in the plot? Adjust your filtering if needed.
```{r}
temperature<-met_files%>%
  group_by(year, site)%>%
  summarize(meanT = mean(`air temp [K]`))

ggplot(temperature, aes(x=year, y=meanT, color=site))+
  geom_line()+
  ggthemes::theme_few()
message("Site SBB_SASP has a higher yearly mean temperature than site SBB_SBSP for all years in the dataset. There is a big jump in temperature from the first year to the following years. Further inspection (in Q6) is needed to determine the suspicious jump in data.")

```
6. Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot?
Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html
```{r}

loopy<-function(data, xyear){
  #y<-as.vector(unique(data[c("year")]))
  met<-data%>%group_by(year, month , site)%>%
  summarize(meanT=mean(`air temp [K]`))%>%
    dplyr::filter(year==xyear)
  print(ggplot(met,aes(x=month, y=meanT, color=site))+
            geom_line()+ facet_wrap(xyear))}
  
for (i in 2005:2010){
  loopy(met_files, i)
}
message("From 2005 to 2010 the monthly average temperatures at the Senator Beck Study Plot are never warmer than the Snow Angel Study Plot")

```
Bonus: Make a plot of average daily precipitation by day of year (averaged across all available years). Color each site. 
```{r}
#coloring each site will not work with duplicate site data
met_files$second<-as.Date(with(met_files,paste(month,day,sep="-")),"%m-%d")%>%
format(., "%j")
  pre<-group_by(met_files,second)%>%
  summarize(meanPre = mean(`precip [kg m-2 s-1]`))
    names(pre)=c('Julian_Day', 'Mean_Precip')
ggplot(pre, aes(x=Julian_Day,y=Mean_Precip))+
  geom_point()+
  ggthemes::theme_few()


```
Bonus #2: Use a function and for loop to create yearly plots of precipitation by day of year. Color each site. 
```{r}

Ploopy<-function(data, xyear){
  #y<-as.vector(unique(data[c("year")]))
  met<-data%>%group_by(year, second , site)%>%
  summarize(meanP=mean(`precip [kg m-2 s-1]`))%>%
    dplyr::filter(year==xyear)
    colnames(met)[2]='Julian_Day'
  print(ggplot(met,aes(x=Julian_Day, y=meanP, color=site))+
            geom_point()+ facet_wrap(xyear))}
  
for (i in 2003:2010){
  Ploopy(met_files, i)
}

```

<!--chapter:end:03-Function.Rmd-->

--- 
title: "ESS Final Project"
author: "Jan Sitterson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
# Spatial Data in R
```{r setup4, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
mapviewOptions(fgb=FALSE)

lagos <- lagosne_load()

#Grab the lake centroid info
lake_centers <- lagos$locus

spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326) %>%
  st_transform(2163)

#Subset for plotting
subset_spatial <- spatial_lakes %>%
  slice(1:100) 

subset_baser <- spatial_lakes[1:100,]
I_state <- states %>%
  filter(name == 'Illinois'| name=='Iowa' ) %>%
  #filter(name == 'Iowa')
  st_transform(2163)

mapview(I_state)

```

<!--chapter:end:04-Spatial.Rmd-->

--- 
title: "ESS Final Project"
author: "Jan Sitterson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
# Regressions
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(R.matlab)
library(rnassqs)
```

## Weather Data Analysis

### Load the PRISM daily maximum temperatures

```{r tmax data}

# daily max temperature
# dimensions: counties x days x years
prism <- readMat("data/prismiowa.mat")

# look at county #1
t_1981_c1 <- prism$tmaxdaily.iowa[1,,1]
t_1981_c1[366]
# plot(1:366, t_1981_c1, type = "l")
# 
# ggplot() +
#   geom_line(mapping = aes(x=1:366, y = t_1981_c1)) +
#   theme_bw() +
#   xlab("day of year") +
#   ylab("daily maximum temperature (°C)") +
#   ggtitle("Daily Maximum Temperature, Iowa County #1")


```
```{r tidying up}

# assign dimension names to tmax matrix
dimnames(prism$tmaxdaily.iowa) <- list(prism$COUNTYFP, 1:366, prism$years)

# converted 3d matrix into a data frame
tmaxdf <- as.data.frame.table(prism$tmaxdaily.iowa)

# relabel the columns
colnames(tmaxdf) <- c("countyfp","doy","year","tmax")
tmaxdf <- tibble(tmaxdf)

```

## Temperature trends

### Summer temperature trends: Winneshiek County

```{r temp trends}

tmaxdf$doy <- as.numeric(tmaxdf$doy)
tmaxdf$year <- as.numeric(as.character(tmaxdf$year))

winnesummer <- tmaxdf %>%
  filter(countyfp==191 & doy >= 152 & doy <= 243) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnesummer, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_summertmax <- lm(meantmax ~ year, winnesummer)
#summary(lm_summertmax)

```

### Winter Temperatures - Winneshiek County

```{r winter temps}

winnewinter <- tmaxdf %>%
  filter(countyfp==191 & (doy <= 59 | doy >= 335) & !is.na(tmax)) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnewinter, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_wintertmax <- lm(meantmax ~ year, winnewinter)
#summary(lm_wintertmax)

```

### Multiple regression -- Quadratic time trend

```{r quadratic temp trend}

winnewinter$yearsq <- winnewinter$year^2

lm_wintertmaxquad <- lm(meantmax ~ year + yearsq, winnewinter)
summary(lm_wintertmaxquad)
winnewinter$fitted <- lm_wintertmaxquad$fitted.values

ggplot(winnewinter) +
  geom_point(mapping = aes(x = year, y = meantmax)) +
  geom_line(mapping = aes(x = year, y = fitted)) +
  theme_bw() +
  labs(x = "year", y = "tmax")

```

### Download NASS corn yield data

```{r , results='hide'}

# set our API key with NASS
nassqs_auth(key = "2FCF525A-8D93-3647-9216-07E60D61705D")

# parameters to query on 
params <- list(commodity_desc = "CORN", util_practice_desc = "GRAIN", prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

# download
cornyieldsall <- nassqs_yields(params)

cornyieldsall$county_ansi <- as.numeric(cornyieldsall$county_ansi)
cornyieldsall$yield <- as.numeric(cornyieldsall$Value)

# clean and filter this dataset
cornyields <- select(cornyieldsall, county_ansi, county_name,county_code, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
cornyields <- tibble(cornyields)

```

## Assignment

### Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend?
```{r}
winne<- cornyieldsall%>%
  filter(county_name=='WINNESHIEK')
Winne_CY <- tibble(winne)

Winne_CY$yield <- as.numeric(Winne_CY$yield)

ggplot(Winne_CY, mapping = aes(x=year, y=yield))+
  geom_point()+
  theme_bw()+
  geom_smooth(method = lm)+
  xlab("Year")+
  ylab("Yield")+
  ggtitle("Corn Yields in Winneshiek County")
  
message("There is an increasing linear trend between year and yield.")

```
### Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? 
```{r}

Winne_CY$yearsq <- Winne_CY$year^2

lm_winnequad <- lm(yield ~ year + yearsq, Winne_CY)
summary(lm_winnequad)
Winne_CY$fitted <- lm_winnequad$fitted.values


ggplot(Winne_CY) +
  geom_point(mapping = aes(x = year, y = yield)) +
  geom_line(mapping = aes(x = year, y = fitted)) +
  theme_bw() +
  labs(x = "year", y = "yield")+
  ggtitle("Winneshiek County Time Trend")

message("There does not seem to be evidence of slowing yield in Winneshiek County because there is a positive quadratic relationship. ")

```
### Question 2 -- Time Series: Let's analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results.
```{r}
q2<-inner_join(winnesummer, Winne_CY)
ggplot(q2,aes(x=meantmax, y=yield))+
  theme_bw()+
  geom_point()+
  labs(x="Mean Max Temperature (°C)", y="Corn Yield")+
  ggtitle("Temperature and Yield for Winneshiek County")


q2$tmp2<-q2$meantmax^2
lm_quad <- lm(yield ~ meantmax + tmp2, q2)
summary(lm_quad)
q2$fittedq <- lm_quad$fitted.values


ggplot(q2)+
  geom_point(mapping = aes(x=meantmax, y=yield))+
  geom_line(mapping = aes(x=meantmax, y=fittedq))+
  theme_bw()+ 
  labs(x="Mean Max Temperature (°C)", y="Corn Yield")+
  ggtitle("Trend of Temperature and Yield for Winneshiek County")

message('Adding a model of Tmax^2 is helpful to interperte the trends of temperature and its effects on corn yield. From this graph you can see as temperature increases yield does as well until a threshold is reached and yield begins to decrease as temperature gets hotter.' )


```
### Question 3 -- Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results.
```{r}

colnames(cornyields)[1]="countyfp"
cornyields$countyfp<- as.numeric(cornyields$countyfp)
tmaxdf$countyfp<- as.numeric(tmaxdf$countyfp)

yield18<- cornyields%>%
  filter(year=='2018')
temp18<-tmaxdf%>%
  filter(year=='2018')


jd18<-inner_join(yield18, temp18, by ="countyfp")%>%
  filter(!is.na(tmax))%>%
  group_by(countyfp, yield)%>%
  summarise(meanTmax=mean(tmax))

ggplot(mapping = aes(x=jd18$meanTmax, y=jd18$yield))+
  geom_point()+
  ggtitle("2018 Temperature and Yield Analysis")+
  theme_bw()+
  labs(x="Mean Max Temperature (°C)", y="Corn Yield")+
  geom_smooth(method = lm)

message('There does not seem to be much of a trend between temperature and corn yield over all of the counties in 2018. When a linear model if fitted to the data you can see a slight decreasing trend in temperature vs yield. ')


```
### Question 4 -- Panel: One way to leverage multiple time series is to group all data into what is called a "panel" regression. Convert the county ID code ("countyfp" or "county_ansi") into factor using as.factor, then include this variable in a regression using all counties' yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model.
```{r}

summer <- tmaxdf %>%
  filter(doy >= 152 & doy <= 243) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

combo<- inner_join(cornyields, summer, by='year')
combo$fac<- as.factor(combo$countyfp)
combo$temp2<-combo$meantmax^2
lm_combo<-lm(yield~meantmax+temp2+year+fac, combo)
summary(lm_combo)
combo$fitted<-lm_combo$fitted.values

ggplot()+
  geom_point(combo, mapping=aes(x=fitted, y=yield))+
  geom_smooth(combo, mapping=aes(x=fitted, y=yield),method = lm)+
  theme_bw()+
  labs(x='Predicted Yield', y='Actual Yield')+
  ggtitle("Actual Yield and fitted yield")

message('The model fits yield based on multiple variables including mean max temp, temperature squared, each county, and each year. The coefficients for temperature is positive but the coefficient for temp^2 is negative. The graph shows how well the modeled predicts values for yield, it is not quite a one to one relationship but there is a linear trend.')

```
### Question 5 -- Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years.
```{r, include=FALSE, echo=TRUE, results='hide'}
#how to hide download from knit? 
nassqs_auth(key = "2FCF525A-8D93-3647-9216-07E60D61705D")

# parameters to query on 
params <- list(commodity_desc = "SOYBEANS",  prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

# download
soyall <- nassqs_yields(params)

soyall$county_ansi <- as.numeric(soyall$county_ansi)
soyall$yield <- as.numeric(soyall$Value)

# clean and filter this dataset
soy <- select(soyall, county_ansi, county_name,county_code, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
soy <- tibble(soy)

ggplot(soy%>%
         filter(county_ansi==21))+
  geom_point( mapping= aes(x=year, y=yield))+
  ggtitle("Soybean Yields in Buena Vista")+
  theme_bw()+
  geom_smooth(aes(x=year, y=yield),method = lm)+
  labs(x="Year", y="Yield")
message('There is a steady increase in soybean yield over time in the Buena Vista county.')

```
### Bonus: Find a package to make a county map of Iowa displaying some sort of information about yields or weather. Interpret your map.
```{r}
# library(USAboundaries)
# states <- us_states()
# Iowa<- states%>%
#   filter(name=="Iowa")
# 
# ggplot(data = d[year == 2016 & state == 'Iowa'],
#     mapping = aes(x = long, y = lat, group = group)) +
#     geom_polygon(aes(fill = value), color = "black", size = 0.1) +
#     geom_polygon(data = polygon_state[state == 'missouri'], col = 'black', fill = NA) +
#     scale_fill_gradientn(name = 'Yield bu/ac',
#         colors = brewer.pal(n = 11, name = 'RdYlGn')) +
#     coord_map('mercator') +
#     theme_bw()
```
### Bonus #2: Challenge question - map trends in corn yields by county across Iowa. Interpret your map.
```{r}
```

<!--chapter:end:05-Regression.Rmd-->

--- 
title: "ESS Final Project"
author: "Jan Sitterson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
## TSS Model

```{r}
tss_boost <- booster(pred = 'TSS',df = wq_sr)

```



### TSS plot


```{r}

boosted <- function(df = wq_sr,pred='TSS',title='Total Suspended Solids',
                    features = predictors){
  
  non_nas <- (!is.na(df[,pred]))
  
  #remove nas
  df = df[non_nas,]
  
  
  #Sample 60% of the data. 
  train <- df %>%
    sample_frac(0.6) 
  
  #Keep only data that is not in train
  #How could we make this safer (spatiotemporal robustness)
  test <- df %>%
    anti_join(.,train,by='index')
  
  
  # Actual boosting model
  ag_mod <- xgboost(data=train %>%
                    dplyr::select(features) %>% 
                      as.matrix(.),
                  label = train %>% pull(pred) %>% log10(.),
                  nthread=4,
                  max_depth=4,
                  eta=0.1,
                  gamma = 0.1,
                  nrounds=300,
                  subsample = 0.5, #best_par['subsample'], # 0.5,
                  colsample_bytree = 0.5,  #0.5,
                  min_child_weight = 1, 
                  lambda = 3, #3
                  print_every_n = 100)
  
  #Tune ntree, k, numcut, bands that you use, etc...
  
  
  #apply predictions. 
  test <- test %>% 
    mutate(bpred= 10^predict(ag_mod,test %>%
                               dplyr::select(features) %>% 
                      as.matrix(.)))
  #Optional for log
  #test[,pred] = 10^test[,pred]
  
  #Remove NAs
  test <- test %>%
    filter(!is.na(pred)) %>%
    as.data.frame()
  
  error <- 
    tibble(rmse=Metrics::rmse(test$bpred,test[,pred]),
                       mdae=Metrics::mdae(test$bpred,test[,pred]),
                       mape=Metrics::mape(test$bpred,test[,pred]),
                       bias=Metrics::bias(test$bpred,test[,pred]))


g2 <- ggplot(test,
         aes_string(x=pred,y='bpred',color='year'))  +
    geom_point() + 
    geom_abline(intercept=0,slope=1,color='red') +
    labs(x='Measured',y='Predicted') + 
    theme_few() +
  scale_color_viridis_c() + 
     scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                labels = trans_format("log10", math_format(10^.x)))  +
       scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                labels = trans_format("log10", math_format(10^.x))) + 
  ggtitle(title)


return(list(g2,error,ag_mod))
}
```


### TSS Evaluation

```{r}
set.seed(2020526) ## Makes the work reproducible, but you can hack this!
tss_boost <- boosted(df = wq_sr)

tss_boost[[1]]
tss_boost[[2]]

```

<!--chapter:end:06-MachineL.Rmd-->

